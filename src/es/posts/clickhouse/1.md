---
# This is the title of the article
title: 'Construyendo un pipeline de datos: De MySQL a Clickhouse con Kafka'
# You can customize cover image
cover: /assets/images/cover1.jpg
# This is the icon of the page
icon: file
# This control sidebar order
order: 1
# Set author
author: Leandro Gutierrez
# Set writing time
date: 2023-11-18
# A page can have multiple categories
category:
  - Bases de Datos
# A page can have multiple tags
tag:
  - Bases de Datos
  - Ingenieria de datos
  - Analítica
# this page is sticky in article list
sticky: true
# this page will appear in starred articles
star: true

disableCopy: true
---

Los motores de reportes son una pieza fundamental de cualquier sistema de información. Permiten a los usuarios consultar y analizar datos de forma rápida y sencilla, lo que les ayuda a tomar mejores decisiones.

En este post vamos a ver cómo sincronizar una base de datos transaccional MySQL con un motor columnar orientado a la analítica, ClickHouse. Este enfoque nos permitirá crear un motor de reportes escalable y eficiente, capaz de manejar grandes volúmenes de datos.

<!-- more -->

## "Necesitamos Big Data"
A diario vemos crecer la cantidad de información que almacenamos, traficamos y procesamos. Imaginemos por un momento que tenemos la dificil tarea de disponibilizar métricas de efectividad de un nuevo feature en el frontend de uno de los sitios de reproduccion audiovisual mas utilizado, feature que no solo impacta en el equipo encargado del desarrollo, sino que tambien concierne a un conjunto de equipos vecinos en la constelación de servicios intervinientes. En ese conjunto se encuentra el equipo encargado del computo puro y duro, allí nosotros, tratemos de por un momento dimensionar la magnitud del/la problema/solución: imaginemos 1 millon de usuarios diarios, a los cuales a un X porcentaje le exponemos la nueva funcionalidad, y con la cual se interacciona al menos 4 veces durante la sesion. Si nuestro test A/B determina una distribución 50/50, una de las mitades no logueará ninguna actividad mientras que la otra al menos obtendremos 4 logs al dia, 2M logs al día, ergo 60M de logs al mes. Imaginemos que al finalizar el periodo de nuestro experimento, luego de 3 meses, queremos validar la eficacia de nuestro feature, estaremos procesando 180M de filas. 

En el mejor de los casos cada fila contendrá toda la informacion desnormalizada ya lista para comenzar a malear, en el mas desagradable la información estará normalizada y será nuestro trabajo el enrichment previo. No siempre es posible ver a tiempo el crecimiento exponencial en la producción de nueva información, y mucho menos la necesidad de formar equipos dedicados a obtención, limpieza y tratamiento de ella. Usualmente la inercia evolutiva natural en terminos de vida de un proyecto de software, nos lleva a puntos limítes donde es necesario replantearnos como enfocarnos en esta problematica, queda todo esto mejor contextualizado sobre todo para lo de la generación que vimos "crujir" el tradicional aproach monolítico, y fuimos parte del paso a servicios distribuidos escalables. Ahora que esta todo distribuido, ¿donde lo juntamos para procesarlo?, mientras que desde la otra oficina indican "Necesitamos acceder a más información, más rápido" (¿lo necesitamos?).

Dependiendo el tipo de solución que el software esté ofreciendo tanto su arquitectura como infraestructura pueden haber ido mutando durante el tiempo. En general (no digo siempre) se parte de una base de datos relacional, las cuales suelen ser simples de comprender, montar y manipular; y son quizás el primer punto de contacto que un programador suele tener al toparse con el mundo del software. Vale la pena mencionar que cualquier solución que requiera procesar transacciones usualmente almacenará su información en una Base de datos Transaccional, como pueden ser MySQL, MariaDB, SQL Server, Oracle. Hoy por hoy, quizás, sonaría raro loguear actividad sobre la interacción de un usuario con el frontend en una base de datos transaccional, pero a modo de ejemplo ilustrativo de un pipeline en la vida real vamos a suponer que nuestro proyecto nace sobre un MySQL Server y que el logueo de cada interacción se realiza en ésta DBMS. Como mencionamos en nuestro ejemplo estaremos en el peor de los casos analizando trimestralente el rendimiento de nuestro feature con cerca de 180M de filas. Si venimos en un proceso evolutivo general, problablemente hace ya tiempo la compañia se haya percatado de la necesidad de "desdoblar" lecutra y escritura en la db relacional. Probablemente exista una replica en caliente mediante alguno de los mecanismos standares de sincronización que ofrece el motor. De todos modos, llegado el momento de procesar 180M de registros y concurriendo no solo esta consulta sino el flujo normal de inserts, updates y selects probablemente entendamos que necesitamos pasar a una solución un tanto mas compleja para hacerle la vida mas facil a quienes toman decisiones.

## RDBMS vs OLAP
Las bases de datos transaccionales relacionales (RDBMS) están diseñadas para el procesamiento de transacciones, que es el conjunto de operaciones (INSERT, UPDATE, DELETE) que se realizan para completar una acción o híto en el negocio. Las RDBMS son muy eficientes en el procesamiento de transacciones, pero no están optimizadas para el análisis de grandes volúmenes de datos.

Como subconjunto de las Base de Datos Transaccionales (TDD por sus siglas en inglés - Transacional Due Diligense), las RDBMS ofrecen:
- Transacciones ACID: Las TDD garantizan que las transacciones se completen de forma consistente, incluso si se producen errores. Esto es importante para aplicaciones que requieren datos fiables, como las aplicaciones financieras o las aplicaciones de comercio electrónico.
- Integridad referencial: Las TDD permiten establecer relaciones entre tablas, lo que ayuda a garantizar la integridad de los datos. Esto es importante para aplicaciones que requieren datos consistentes, como las aplicaciones de gestión de clientes o las aplicaciones de inventario.
- Eficiencia para el procesamiento de transacciones: Las TDD están optimizadas para operar transacciones. Esto es importante para aplicaciones que requieren un alto rendimiento transaccional.

## Column-Oriented vs Row-Oriented
- En un sistema de gestión de bases de datos orientado a filas, todos los datos de una fila se almacenan físicamente uno al lado del otro.
![row-oriented.gif](/assets/images/row-oriented.gif)
- En un sistema de gestión de bases de datos orientado a columnas, todos los valores de una columna son almacenados de manera contigua.
![column-oriented.gif](/assets/images/column-oriented.gif)

## Clickhouse
ClickHouse es un sistema de gestión de bases de datos (DBMS) SQL de alto rendimiento y orientado a columnas para procesamiento analítico en línea (OLAP). Está disponible tanto como software de código abierto como en una oferta en la nube.

### ENGINE MergeTree
1. Puede ser considerado el engine por defecto de Clickhouse.
2. Ordena los datos por indice primario ([sparse index](https://www2.cs.sfu.ca/CourseCentral/354/zaiane/material/notes/Chapter11/node5.html)).
3. Los datos pueden ser particionados (partitions + parts).
4. Sentencia de creación:
	```
    CREATE TABLE [IF NOT EXISTS] [db.]table_name [ON CLUSTER cluster]
    (
        name1 [type1] [[NOT] NULL] [DEFAULT|MATERIALIZED|ALIAS|EPHEMERAL expr1] [COMMENT ...] [CODEC(codec1)] [TTL expr1] [PRIMARY KEY],
        name2 [type2] [[NOT] NULL] [DEFAULT|MATERIALIZED|ALIAS|EPHEMERAL expr2] [COMMENT ...] [CODEC(codec2)] [TTL expr2] [PRIMARY KEY],
        ...
        INDEX index_name1 expr1 TYPE type1(...) [GRANULARITY value1],
        INDEX index_name2 expr2 TYPE type2(...) [GRANULARITY value2],
        ...
        PROJECTION projection_name_1 (SELECT <COLUMN LIST EXPR> [GROUP BY] [ORDER BY]),
        PROJECTION projection_name_2 (SELECT <COLUMN LIST EXPR> [GROUP BY] [ORDER BY])
    ) ENGINE = MergeTree()
    ORDER BY expr
    [PARTITION BY expr]
    [PRIMARY KEY expr]
    [SAMPLE BY expr]
    [TTL expr
        [DELETE|TO DISK 'xxx'|TO VOLUME 'xxx' [, ...] ]
        [WHERE conditions]
        [GROUP BY key_expr [SET v1 = aggr_func(v1) [, v2 = aggr_func(v2) ...]] ] ]
    [SETTINGS name=value, ...]
	```
    - ENGINE — El engine MergeTree() no lleva parámetros.
    - ORDER BY — La clave de ordenamiento (sorting key) - Clickhouse usa la sorting key para determinar como se almacena la información en disco, además sirve en engines de la familia MergeTree para funcionalidades específicas de cada tipo, por ejemplo sirve como clave de agregación en AggregatingMergeTree o de deduplicación en CollapsingMergeTree. Se usa como como clave primaria si PRIMARY KEY no es provista)
    - PARTITION BY — La clave de particionado. Opcional. Por ejemplo si se desea particionar por mes: toYYYYMM(date_column), donde date_column es del tipo de dato Date. Las particiones son  nomencladas de la forma "YYYYMM".
    - PRIMARY KEY — Opcional. Siempre es igual o un prefijo de la sorting key. En muchos casos es innesesario definir el PRIMARY KEY, toma por defecto ORDER BY. Sirve para armar el indice propiamente dicho (primary.idx). 
::: tip ¿Cuando difieren ORDER BY y PRIMARY KEY?
 Si por ejemplo en algun momento se requiere agregar una columna mas a una clave de agregación, puede ser recomendable solo modificar la ORDER BY (o sorting key) mediante un ALTER TABLE, manteniendo la PRIMARY KEY, y por lo tanto su archivo de indices, sin modificar. Ahorrandonos de esta manera una reindexación completa, ya que la antigua PK será prefijo de la nueva sorting key, situación aceptable para el funcionamiento del motor. Obiamente la estrategia va a depender de la cardinalidad y el uso como filtro que se le quiera dar a la nueva columna.
:::


::: tip Sorting key vs Primary key
Sorting key defines order in which data will be stored on disk, while primary key defines how data will be structured for queries. Usually those are the same (and in this case you can omit PRIMARY KEY expression, Clickhouse will take that info from ORDER BY expression). [link](https://medium.com/datadenys/how-clickhouse-primary-key-works-and-how-to-choose-it-4aaf3bf4a8b9#:~:text=ORDER%20BY%20(event%2C%20user_id%2C%20dt)&text=Sorting%20key%20defines%20order%20in,will%20be%20structured%20for%20queries.)
:::
 
#### Ejemplo
```
  CREATE TABLE my_base_raw.transactions_raw(
    `id_transaction` Int64,
    `user_id` Int32,
    `timestamp` DateTime(3),
    `type` String,
    `sequence` string,
    `amount` Decimal(10,2),
    `__ver` Int64) ENGINE = MergeTree()
  ORDER BY (id_transaction)
  PARTITION BY toYYYYMM(timestamp)
```

#### Particiones e Indices
- A su vez podemos listar las diferentes particiones/parts de cada tabla en  Clickhouse consultando la tabla de sistema `system.parts`.
```
SELECT
    partition,
    name,
    active
FROM system.parts
WHERE (table = 'transactions_raw') AND (partition = '202310')

Query id: 6b6aa9ec-fc61-4217-bd47-a3c4fd9400b5

┌─partition─┬─name────────────────────────┬─active─┐
│ 202310    │ 202310_4475842_4490464_1414 │      1 │
│ 202310    │ 202310_4490465_4511646_1317 │      1 │
│ 202310    │ 202310_4511647_4515242_1330 │      1 │
│ 202310    │ 202310_4515243_4515584_174  │      0 │
│ 202310    │ 202310_4515243_4515585_175  │      0 │
│ 202310    │ 202310_4515243_4515593_183  │      0 │
│ 202310    │ 202310_4515243_4515594_184  │      0 │
│ 202310    │ 202310_4515243_4515595_185  │      1 │
│ 202310    │ 202310_4515595_4515595_0    │      0 │
│ 202310    │ 202310_4515596_4515596_0    │      1 │
│ 202310    │ 202310_4515597_4515597_0    │      1 │
│ 202310    │ 202310_4515598_4515598_0    │      1 │
│ 202310    │ 202310_4515599_4515599_0    │      1 │
└───────────┴─────────────────────────────┴────────┘
```
Desglose del nombre de la parte: 202310_4515243_4515595_185:

- `202310` es el nombre de la partición.
- `4515243` es el número mínimo de la PK del bloque de datos.
- `4515595` es el número máximo de la PK del bloque de datos.
- `185` es la versión de mutación (si una parte ha mutado).

[Lectura ](https://medium.com/datadenys/how-clickhouse-primary-key-works-and-how-to-choose-it-4aaf3bf4a8b9#:~:text=ORDER%20BY%20(event%2C%20user_id%2C%20dt)&text=Sorting%20key%20defines%20order%20in,will%20be%20structured%20for%20queries.)

#### ¿Como funcionan los indices esparcidos?
Dado el siguiente indice dentro de una partición de una tabla:
![primarykeys.jpeg](/assets/images/primarykeys.jpeg)
Si en una query utilizamos los siguientes filtros en la dondición WHERE, la poda o pruning inicial sería:
- CounterID in ('a', 'h') → ranges of marks [0, 3) and [6, 8).
- CounterID IN ('a', 'h') AND Date = 3 → ranges of marks [2, 3) and [7, 8).
- Date = 3 → range of marks [1, 10].

#### Representación gráfica del indice primario y estrategia de almacenamiento
<img src="/assets/images/sparse-primary-indexes.jpg" style="background-color:white">
<img src="/assets/images/sparse-primary-indexes-2.jpg" style="background-color:white">
<img src="/assets/images/sparse-primary-indexes-3.jpg" style="background-color:white">

### ENGINE Kafka
Las tablas definidas con `ENGINE = Kafka` hacen las veces de consumidores de eventos en topics, y las cuales no sirven de almacenamiento permanente. 
### MaterializedViews
En Clickhouse las vistas materializadas (MaterializedViews) funcionan como "triggers" de la tabla fuente de la consulta, es decir la db ofrece una funcionalidad reactiva ante nuevas filas. [Lectura](https://den-crane.github.io/Everything_you_should_know_about_materialized_views_commented.pdf)
